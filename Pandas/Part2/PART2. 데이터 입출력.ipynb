{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1b360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 외부 파일 읽어오기\n",
    "# 판다스는 다양한 형태의 외부 파일을 읽어와서 데이터프레임으로 변환하는 함수를 제공\n",
    "# 반대로 데이터프레임을 다양한 유형의 파일로 저장할 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf117ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   c0  c1  c2  c3\n",
      "0   0   1   4   7\n",
      "1   1   2   5   8\n",
      "2   2   3   6   9\n",
      "\n",
      "\n",
      "    0   1   2   3\n",
      "0  c0  c1  c2  c3\n",
      "1   0   1   4   7\n",
      "2   1   2   5   8\n",
      "3   2   3   6   9\n",
      "\n",
      "\n",
      "   c0  c1  c2  c3\n",
      "0   0   1   4   7\n",
      "1   1   2   5   8\n",
      "2   2   3   6   9\n",
      "\n",
      "\n",
      "    c1  c2  c3\n",
      "c0            \n",
      "0    1   4   7\n",
      "1    2   5   8\n",
      "2    3   6   9\n"
     ]
    }
   ],
   "source": [
    "# 1-1. CSV 파일\n",
    "# CSV 파일 -> 데이터프레임 : pandas.read_csv(\"파일 경로(이름)\")\n",
    "# 데이터 값을 쉼표(,)로 구분하고 있다는 의미로 CSV(Comma Separated Values)라고 부르는 텍스트 파일\n",
    "# 쉼표로 열을 구분하고 줄바꿈으로 행을 구분\n",
    "# header 옵션은 데이터프레임의 열 이름으로 사용할 행을 지정\n",
    "# header 옵션이 없으면 CSV 파일의 첫 행의 데이터가 열 이름이 됨 (디폴트)\n",
    "# index_col 옵션은 데이터프레임의 행 인덱스가 되는 열을 지정\n",
    "# index_col 옵션을 지정하지 않으면 행 인덱스는 정수 0, 1, 2가 자동 지정\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = './read_csv_sample.csv' # 현재 폴더인 경우 './' , 이전 폴더인 경우 '../'\n",
    "\n",
    "df1 = pd.read_csv(file_path) # 아무런 옵션이 없으므로 첫 행이 열 이름, 행 인덱스는 자동 지정\n",
    "print(df1)\n",
    "print('\\n')\n",
    "\n",
    "df2 = pd.read_csv(file_path, header = None) # 열을 지정하지 않음, 즉 정수로 지정됨\n",
    "print(df2)\n",
    "print('\\n')\n",
    "\n",
    "df3 = pd.read_csv(file_path, index_col = None) # 행 인덱스를 지정하지 않음, 즉 정수로 지정됨\n",
    "print(df3)\n",
    "print('\\n')\n",
    "\n",
    "df4 = pd.read_csv(file_path, index_col = 'c0') # 기존에 있는 열을 행 인덱스로 지정\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeda7176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   열1  열2  열3  열4\n",
      "0   0   1   4   7\n",
      "1   1   2   5   8\n",
      "2   2   3   6   9\n",
      "\n",
      "\n",
      "   1  2  5  8\n",
      "0  2  3  6  9\n",
      "\n",
      "\n",
      "   c0  c1  c2  c3\n",
      "0   1   2   5   8\n",
      "\n",
      "\n",
      "   c0  c1  c2  c3\n",
      "0   0   1   4   7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gram\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일에 따라서는 쉼표 대신 탭, 공백으로 텍스트를 구분하기도 함\n",
    "# 이 때는 구분자 옵션을 알맞게 입력해야 함\n",
    "# sep : 텍스트 데이터를 필드별로 구분하는 문자\n",
    "# names : 열 이름으로 사용할 문자열의 리스트\n",
    "# skiprows : 처음 몇 줄을 skip할 것인지를 설정(숫자 입력), skip하려는 행의 번호를 담은 리스트로 설정 가능(예: [1,3,5])\n",
    "# parse_date : 날짜 텍스트를 datatime64(일자시간타입)로 변환할 것인지 설정(기본값은 False)\n",
    "# skipfooter : 마지막 몇 줄을 skip할 것인지 설정(숫자 입력)\n",
    "# encoding : 텍스트 인코딩 종류를 지정(예 : 'utf-8')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. names : 열 이름으로 사용할 문자열 리스트 지정\n",
    "df1 = pd.read_csv('./read_csv_sample.csv', header = 0, names = ['열1', '열2', '열3', '열4'])\n",
    "print(df1)\n",
    "print('\\n')\n",
    "\n",
    "# 2. skiprows : 처음 몇 줄을 skip할 건지, 리스트로 입력하면 해당 줄만 skip\n",
    "# 초기 데이터에 대해서 생각하기\n",
    "df2 = pd.read_csv('./read_csv_sample.csv', skiprows = 2)\n",
    "print(df2)\n",
    "print('\\n')\n",
    "\n",
    "df3 = pd.read_csv('./read_csv_sample.csv', skiprows = [1, 3])\n",
    "print(df3)\n",
    "print('\\n')\n",
    "\n",
    "# 3. skipfooter : 마지막 몇 줄을 skip할 건지\n",
    "df4 = pd.read_csv('./read_csv_sample.csv', skipfooter = 2)\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb924bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  전력량 (억㎾h) 발전 전력별  1990  1991  1992  1993  1994  1995  1996  1997  ...  2007  \\\n",
      "0        남한     합계  1077  1186  1310  1444  1650  1847  2055  2244  ...  4031   \n",
      "1       NaN     수력    64    51    49    60    41    55    52    54  ...    50   \n",
      "2       NaN     화력   484   573   696   803  1022  1122  1264  1420  ...  2551   \n",
      "3       NaN    원자력   529   563   565   581   587   670   739   771  ...  1429   \n",
      "4       NaN    신재생     -     -     -     -     -     -     -     -  ...     -   \n",
      "5        북한     합계   277   263   247   221   231   230   213   193  ...   236   \n",
      "6       NaN     수력   156   150   142   133   138   142   125   107  ...   133   \n",
      "7       NaN     화력   121   113   105    88    93    88    88    86  ...   103   \n",
      "8       NaN    원자력     -     -     -     -     -     -     -     -  ...     -   \n",
      "\n",
      "   2008  2009  2010  2011  2012  2013  2014  2015  2016  \n",
      "0  4224  4336  4747  4969  5096  5171  5220  5281  5404  \n",
      "1    56    56    65    78    77    84    78    58    66  \n",
      "2  2658  2802  3196  3343  3430  3581  3427  3402  3523  \n",
      "3  1510  1478  1486  1547  1503  1388  1564  1648  1620  \n",
      "4     -     -     -     -    86   118   151   173   195  \n",
      "5   255   235   237   211   215   221   216   190   239  \n",
      "6   141   125   134   132   135   139   130   100   128  \n",
      "7   114   110   103    79    80    82    86    90   111  \n",
      "8     -     -     -     -     -     -     -     -     -  \n",
      "\n",
      "[9 rows x 29 columns]\n",
      "\n",
      "\n",
      "          0       1     2     3     4     5     6     7     8     9   ...  \\\n",
      "0  전력량 (억㎾h)  발전 전력별  1990  1991  1992  1993  1994  1995  1996  1997  ...   \n",
      "1         남한      합계  1077  1186  1310  1444  1650  1847  2055  2244  ...   \n",
      "2        NaN      수력    64    51    49    60    41    55    52    54  ...   \n",
      "3        NaN      화력   484   573   696   803  1022  1122  1264  1420  ...   \n",
      "4        NaN     원자력   529   563   565   581   587   670   739   771  ...   \n",
      "5        NaN     신재생     -     -     -     -     -     -     -     -  ...   \n",
      "6         북한      합계   277   263   247   221   231   230   213   193  ...   \n",
      "7        NaN      수력   156   150   142   133   138   142   125   107  ...   \n",
      "8        NaN      화력   121   113   105    88    93    88    88    86  ...   \n",
      "9        NaN     원자력     -     -     -     -     -     -     -     -  ...   \n",
      "\n",
      "     19    20    21    22    23    24    25    26    27    28  \n",
      "0  2007  2008  2009  2010  2011  2012  2013  2014  2015  2016  \n",
      "1  4031  4224  4336  4747  4969  5096  5171  5220  5281  5404  \n",
      "2    50    56    56    65    78    77    84    78    58    66  \n",
      "3  2551  2658  2802  3196  3343  3430  3581  3427  3402  3523  \n",
      "4  1429  1510  1478  1486  1547  1503  1388  1564  1648  1620  \n",
      "5     -     -     -     -     -    86   118   151   173   195  \n",
      "6   236   255   235   237   211   215   221   216   190   239  \n",
      "7   133   141   125   134   132   135   139   130   100   128  \n",
      "8   103   114   110   103    79    80    82    86    90   111  \n",
      "9     -     -     -     -     -     -     -     -     -     -  \n",
      "\n",
      "[10 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1-2. Excel 파일\n",
    "# Excel 파일 -> 데이터프레임 : pandas.read_excel(\"파일 경로(이름)\")\n",
    "# Excel 파일(확장자 : xlsx)의 행과 열은 데이터프레임의 행, 열로 일대일 대응된다\n",
    "# read_excel() 함수의 사용법은 앞에서 살펴본 read.csv()의 사용과 거의 비슷\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel('./남북한발전전력량.xlsx', engine = 'openpyxl') # header = 0이 디폴트, 데이터의 첫 행이 열 이름으로 !\n",
    "df2 = pd.read_excel('./남북한발전전력량.xlsx', engine = 'openpyxl', header = None) # 정수형 인덱스 0, 1, 2 .. 가 열 이름으로 !\n",
    "\n",
    "print(df1)\n",
    "print('\\n')\n",
    "print(df2)\n",
    "\n",
    "# 실행 환경에 따라서는 Excel 파일 데이터를 추출을 지원하는 xlrd 라이브러리와 openpyxl 라이브러리 설치가 필요할 수 있음\n",
    "# xlsx 확장자를 갖는 경우, engine 옵션에 'openpyxl' / xls 확장자를 갖는 경우 'xlrd'를 옵션으로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78692144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name  year        developer opensource\n",
      "pandas           2008    Wes Mckinneye       True\n",
      "NumPy            2006  Travis Oliphant       True\n",
      "matplotlib       2003   John D. Hunter       True\n",
      "\n",
      "\n",
      "Index(['pandas', 'NumPy', 'matplotlib'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 1-3. JSON 파일\n",
    "# JSON 파일 -> 데이터프레임 : pandas.read_json(\"파일 경로(이름)\")\n",
    "# JSON 파일(확장자: .json)은 데이터 공유를 목적으로 개발된 특수한 파일 형식\n",
    "# 파이썬 딕셔너리와 비슷하게 key:value 구조를 갖는데, 구조가 중첩되는 방식에 따라 다르게 적용\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('./read_json_sample.json')\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(df.index) # JSON 파일의 \"name\" 데이터가 인덱스로 지정됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b701bc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "\n",
      "\n",
      "tables[0]\n",
      "   Unnamed: 0  c0  c1  c2  c3\n",
      "0           0   0   1   4   7\n",
      "1           1   1   2   5   8\n",
      "2           2   2   3   6   9\n",
      "\n",
      "\n",
      "tables[1]\n",
      "         name  year        developer  opensource\n",
      "0       NumPy  2006  Travis Oliphant        True\n",
      "1  matplotlib  2003   John D. Hunter        True\n",
      "2      pandas  2008    Wes Mckinneye        True\n",
      "\n",
      "\n",
      "            year        developer  opensource\n",
      "name                                         \n",
      "NumPy       2006  Travis Oliphant        True\n",
      "matplotlib  2003   John D. Hunter        True\n",
      "pandas      2008    Wes Mckinneye        True\n"
     ]
    }
   ],
   "source": [
    "# 2. 웹(web)에서 가져오기\n",
    "\n",
    "# 2-1. HTML 웹 페이지에서 표 속성 가져오기\n",
    "# HTML 표 속성 읽기 : pandas.read_html(\"웹주소\" 또는 \"HTML 파일 경로(이름)\")\n",
    "# HTML (Hypertext Markup Language,하이퍼텍스트 마크업 언어)는 우리가 보는 웹페이지가 어떻게 구조화되어 있는지 알 수 있도록 하는 마크업 언어\n",
    "# 판다스 read_html() 함수는 HTML 웹 페이지에 있는 <table> 태그에서 표 형식의 데이터를 모두 찾아 데이터프레임으로 변환\n",
    "# 표 데이터들은 각각 별도의 데이터프레임으로 변환되기 때문에 여러 개의 데이터프레임을 원소로 갖는 리스트가 반환됨\n",
    "# read_html() 함수를 이용하여 웹 페이지의 표 정보를 파싱하려면, url을 따옴표 안에 입력\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = \"./sample.html\"\n",
    "\n",
    "tables = pd.read_html(url) # 변수 tables에는 2개의 데이터프레임을 원소로 갖는 리스트가 저장\n",
    "print(len(tables))\n",
    "print('\\n')\n",
    "\n",
    "for i in range(len(tables)):\n",
    "    print(\"tables[%s]\" % i)\n",
    "    print(tables[i])\n",
    "    print('\\n') # tables 리스트의 원소를 iteration하면서 각각 화면 출력\n",
    "    \n",
    "df = tables[1] # 파이썬 패키지 정보가 들어 있는 2번째 표를 인덱싱하여 df 변수에 저장\n",
    "df.set_index(['name'], inplace = True) # df의 열 'name'을 새로운 행 인덱스로 설정\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d820e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 2-2. 웹 스크래핑\n",
    "# BeautifulSoup 등 웹 스크래핑 도구로 수집한 데이터를 판다스 데이터프레임으로 정리하는 방법 설명\n",
    "# 스크래핑한 내용을 파이썬 리스트, 딕셔너리 등으로 정리한 뒤 DataFrame() 함수에 리스트나 딕셔너리 형태로 전달하여 데이터프레임으로 변환\n",
    "\n",
    "# etfs[etf_ticker[0]] = [etf_market[0], etf_name[0]]와 같이 리스트를 원소로 갖는 딕셔너리를 정의하는 방법을 반드시 기억\n",
    "# 왼쪽의 딕셔너리 키는 열 이름이 되고, 오른쪽 리스트는 열 데이터가 됨\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd \n",
    "\n",
    "# 위키피디아 미국 ETF 웹 페이지에서 필요한 정보를 스크래핑하여 딕셔너리 형태로 변수 etfs에 저장\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_American_exchange-traded_funds\"\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.text, 'lxml')   \n",
    "rows = soup.select('div > ul > li')\n",
    "    \n",
    "etfs = {}\n",
    "for row in rows:\n",
    "    \n",
    "    try:\n",
    "        etf_name = re.findall('^(.*) \\(NYSE', row.text)\n",
    "        etf_market = re.findall('\\((.*)\\|', row.text)\n",
    "        etf_ticker = re.findall('NYSE Arca\\|(.*)\\)', row.text)\n",
    "        \n",
    "        if (len(etf_ticker) > 0) & (len(etf_market) > 0) & (len(etf_name) > 0):\n",
    "            etfs[etf_ticker[0]] = [etf_market[0], etf_name[0]]\n",
    "\n",
    "    except AttributeError as err:\n",
    "        pass    \n",
    "\n",
    "# etfs 딕셔너리 출력\n",
    "print(etfs)\n",
    "print('\\n')\n",
    "\n",
    "# etfs 딕셔너리를 데이터프레임으로 변환\n",
    "df = pd.DataFrame(etfs)\n",
    "print(df)\n",
    "\n",
    "\n",
    "# 데이터베이스에서 판다스로 데이터를 가져올 수 있을까 ?\n",
    "# 판다스 read_sql() 함수를 이용하면 SQL 쿼리를 가지고 데이터베이스로부터 데이터를 불러올 수 있음\n",
    "# 이 때 읽어온 데이터는 데이터프레임 포맷으로 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b04ef0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 고려대학교\n",
      "2 부산대학교\n",
      "3 인하대학교\n",
      "\n",
      "\n",
      "              위도          경도\n",
      "고려대학교  37.590799  127.027777\n",
      "부산대학교  35.233512  129.081005\n",
      "인하대학교  37.450022  126.653488\n"
     ]
    }
   ],
   "source": [
    "# 2-3. API 활용하여 데이터 수집하기\n",
    "# API를 통해서 수집한 데이터를 판다스 자료구조로 변환하는 방법을 알아봄\n",
    "# 대부분 API는 판다스에서 쉽게 읽어올 수 있는 파일 형식(csv, html, xml, ...)을 지원\n",
    "# 따라서, API를 통해 가져온 데이터를 판다스 데이터프레임으로 손쉽게 변환 가능\n",
    "\n",
    "# 구글 지오코딩 API로 예를 들어 설명\n",
    "\n",
    "import googlemaps\n",
    "import pandas as pd\n",
    "\n",
    "my_key = \"---API 키 노출 금지---\"\n",
    "\n",
    "maps = googlemaps.Client(key=my_key)\n",
    "\n",
    "lat = [] # 위도\n",
    "lng = [] # 경도\n",
    "places = ['고려대학교', '부산대학교', '인하대학교'] # 장소 리스트\n",
    "\n",
    "i = 0\n",
    "for place in places:\n",
    "    i += 1\n",
    "    try:\n",
    "        print(i, place)\n",
    "        geo_location = maps.geocode(place)[0].get(\"geometry\")\n",
    "        lat.append(geo_location['location']['lat'])\n",
    "        lng.append(geo_location['location']['lng'])\n",
    "    except:\n",
    "        lat.append('')\n",
    "        lng.append('')\n",
    "        print(i)\n",
    "        \n",
    "df = pd.DataFrame({'위도':lat, '경도':lng}, index = places)\n",
    "print('\\n')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fc6a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      algol basic c++\n",
      "name                 \n",
      "Jerry     A     C  B+\n",
      "Riah     A+     B   C\n",
      "Paul      B    B+  C+\n"
     ]
    }
   ],
   "source": [
    "# 4. 데이터 저장하기\n",
    "\n",
    "# 4-1. CSV 파일로 저장\n",
    "# CSV 파일로 저장 : DataFrame 객체.to_csv(\"파일 이름(경로)\")\n",
    "# 판다스 데이터프레임은 2차원 배열로 구조화된 데이터이기 때문에 2차원 구조를 갖는 CSV 파일로 변환 가능\n",
    "# 데이터프레임을 CSV 파일로 저장하려면 to_csv() 메소드를 적용\n",
    "# CSV 파일을 저장할 파일 경로와 파일명(확장자 포함)을 따옴표 안에 입력\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'name':['Jerry','Riah','Paul'],\n",
    "        'algol':['A','A+','B'],\n",
    "        'basic':['C','B','B+'],\n",
    "        'c++':['B+','C','C+']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('name',inplace = True)\n",
    "print(df)\n",
    "\n",
    "df.to_csv(\"./df_sample.csv\") # 파일을 열어보면 쉼표와 줄바꿈으로 구분되는 2차원 구조가 확인됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f802fd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      algol basic c++\n",
      "name                 \n",
      "Jerry     A     C  B+\n",
      "Riah     A+     B   C\n",
      "Paul      B    B+  C+\n"
     ]
    }
   ],
   "source": [
    "# 4-2. JSON 파일로 저장\n",
    "# JSON 파일로 저장 : DataFrame 객체.to_json(\"파일 이름(경로)\")\n",
    "# 데이터프레임을 JSON 파일로 저장하려면 to_json() 메소드를 이용\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'name':['Jerry','Riah','Paul'],\n",
    "        'algol':['A','A+','B'],\n",
    "        'basic':['C','B','B+'],\n",
    "        'c++':['B+','C','C+']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('name', inplace = True)\n",
    "print(df)\n",
    "\n",
    "df.to_json(\"./df_sample.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "516e56cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      algol basic c++\n",
      "name                 \n",
      "Jerry     A     C  B+\n",
      "Riah     A+     B   C\n",
      "Paul      B    B+  C+\n"
     ]
    }
   ],
   "source": [
    "# 4-3. Excel 파일로 저장\n",
    "# Excel 파일로 저장 : DataFrame 객체.to_excel(\"파일 이름(경로)\")\n",
    "# 데이터프레임은 Excel 파일과 아주 유사한 구조를 가짐\n",
    "# 데이터프레임의 행과 열은 Excel 파일의 행과 열로 일대일 대응됨\n",
    "# 데이터프레임을 Excel 파일로 저장할 때는 to_excel() 메소드를 적용\n",
    "# 단, to_excel() 메소드를 사용하려면 openpyxl 라이브러리를 사전에 설치해야 함 (import openpyxl)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'name':['Jerry','Riah','Paul'],\n",
    "        'algol':['A','A+','B'],\n",
    "        'basic':['C','B','B+'],\n",
    "        'c++':['B+','C','C+']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('name', inplace = True)\n",
    "print(df)\n",
    "\n",
    "df.to_excel(\"./df_sample.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d54a6a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      algol basic c++\n",
      "name                 \n",
      "Jerry     A     C  B+\n",
      "Riah     A+     B   C\n",
      "Paul      B    B+  C+\n",
      "\n",
      "\n",
      "    c1  c2  c3  c4\n",
      "c0                \n",
      "1    4   7  10  13\n",
      "2    5   8  11  14\n",
      "3    6   9  12  15\n"
     ]
    }
   ],
   "source": [
    "# 4-4. 여러 개의 데이터프레임을 하나의 Excel 파일로 저장\n",
    "# 데이터프레임 여러 개를 Excel 파일로 저장 : pandas.ExcelWriter(\"파일 이름(경로)\")\n",
    "# 판다스 ExcelWriter() 함수는 Excel 워크북 객체를 생성 (이 때, 워크북은 하나의 엑셀 파일이라고 생각)\n",
    "# 데이터프레임에 to_excel() 메소드를 적용할 때 삽입하려는 워크북 객체를 인자로 전달\n",
    "# 또한, sheet_name 옵션에 Excel 파일의 시트이름을 입력하여 삽입되는 시트 위치 지정 가능\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data1 = {'name':['Jerry','Riah','Paul'],\n",
    "        'algol':['A','A+','B'],\n",
    "        'basic':['C','B','B+'],\n",
    "        'c++':['B+','C','C+']}\n",
    "\n",
    "data2 = {'c0':[1,2,3],\n",
    "         'c1':[4,5,6],\n",
    "         'c2':[7,8,9],\n",
    "         'c3':[10,11,12],\n",
    "         'c4':[13,14,15]}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df1.set_index('name', inplace = True)\n",
    "print(df1)\n",
    "print('\\n')\n",
    "\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2.set_index('c0', inplace = True)\n",
    "print(df2)\n",
    "\n",
    "writer = pd.ExcelWriter('./df_excelwriter.xlsx') #  ExcelWriter() 함수로 생성한 워크북 객체를 writer 변수에 저장\n",
    "df1.to_excel(writer, sheet_name = 'sheet1')\n",
    "df2.to_excel(writer, sheet_name = 'sheet2')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
